{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874a1ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import keras\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba676e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856ce28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8a0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Gundeep Gulati\\Desktop\\Language_Identification_dataset\\dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce4bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f94a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22000 entries, 0 to 21999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      22000 non-null  object\n",
      " 1   language  22000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 343.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2240b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddae14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4f7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 50000\n",
    "max_len = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a5c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(list(df['Text']))\n",
    "train_df = tokenizer.texts_to_sequences(list(df['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6195bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tf.keras.preprocessing.sequence.pad_sequences(train_df,maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f844c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a783a61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  2170,    82,  3638],\n",
       "       [    0,     0,     0, ...,    16,  4068, 26452],\n",
       "       [    0,     0,     0, ...,     0,     0, 16664],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   118,  1435,   168],\n",
       "       [    0,     0,     0, ...,    16,  2029,   471],\n",
       "       [    0,     0,     0, ...,   178,  6523,     1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d19e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273967"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c2e2c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Estonian\n",
       "1         Swedish\n",
       "2            Thai\n",
       "3           Tamil\n",
       "4           Dutch\n",
       "           ...   \n",
       "21995      French\n",
       "21996        Thai\n",
       "21997     Spanish\n",
       "21998     Chinese\n",
       "21999    Romanian\n",
       "Name: language, Length: 22000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df['language']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3bf5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c5bd3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c46b7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'Chinese',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'Estonian',\n",
       " 'French',\n",
       " 'Hindi',\n",
       " 'Indonesian',\n",
       " 'Japanese',\n",
       " 'Korean',\n",
       " 'Latin',\n",
       " 'Persian',\n",
       " 'Portugese',\n",
       " 'Pushto',\n",
       " 'Romanian',\n",
       " 'Russian',\n",
       " 'Spanish',\n",
       " 'Swedish',\n",
       " 'Tamil',\n",
       " 'Thai',\n",
       " 'Turkish',\n",
       " 'Urdu']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db234dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "949ff70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_languages = df['language'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "286cce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = keras.utils.to_categorical(Y2,num_classes=total_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7bfcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d90309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(train_df,Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05a90f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 500\n",
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b56b31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(input_dim = vocab_size,output_dim = embedding_dims,input_length = max_len),\n",
    "                            tf.keras.layers.Flatten(),\n",
    "                            tf.keras.layers.Dense(total_languages,activation=tf.nn.softmax)\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b45e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 500)          136984000 \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 22)                1100022   \n",
      "=================================================================\n",
      "Total params: 138,084,022\n",
      "Trainable params: 138,084,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e98386",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9c55b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16500 samples\n",
      "Epoch 1/5\n",
      "16500/16500 [==============================] - 515s 31ms/sample - loss: 0.6298 - accuracy: 0.8315\n",
      "Epoch 2/5\n",
      "16500/16500 [==============================] - 523s 32ms/sample - loss: 0.1179 - accuracy: 0.9476\n",
      "Epoch 3/5\n",
      "16500/16500 [==============================] - 527s 32ms/sample - loss: 0.0901 - accuracy: 0.9535\n",
      "Epoch 4/5\n",
      "16500/16500 [==============================] - 527s 32ms/sample - loss: 0.0858 - accuracy: 0.9553\n",
      "Epoch 5/5\n",
      "16500/16500 [==============================] - 558s 34ms/sample - loss: 0.0828 - accuracy: 0.9563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x239cf253390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train),np.array(Y_train),epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "484aeca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/5500 [==============================] - 1s 135us/sample - loss: 0.1668 - accuracy: 0.9342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1668202197382396, 0.9341818]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(X_test),np.array(Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a0ebbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English  [3]\n",
      "French  [5]\n",
      "Dutch  [2]\n",
      "Swedish  [17]\n"
     ]
    }
   ],
   "source": [
    "print(\"English \",le.transform(['English']))\n",
    "print(\"French \",le.transform(['French']))\n",
    "print(\"Dutch \",le.transform(['Dutch']))\n",
    "print(\"Swedish \",le.transform(['Swedish']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd43c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = [\"Once you know all the elements, it's not difficult to pull together a sentence.\"]\n",
    "#text = [\"När du väl känner till alla element är det inte svårt att ta ihop en mening.\"] #swedish\n",
    "text = [\"Als je eenmaal alle elementen kent, is het niet moeilijk om een zin samen te stellen.\"] # Dutch\n",
    "#text =[\"Une fois que vous connaissez tous les éléments, il n'est pas difficile de rassembler une phrase.\"] #French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60060079",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = tokenizer.texts_to_sequences(text)\n",
    "test_text = tf.keras.preprocessing.sequence.pad_sequences(test_text, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c62b7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7824749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dutch']\n",
      "[[6.1012186e-05 5.6895602e-04 9.9741167e-01 1.7087336e-04 3.1848587e-05\n",
      "  4.1141186e-05 4.3521188e-05 4.6991114e-05 2.1377979e-04 8.8911162e-05\n",
      "  2.1953195e-04 4.7906600e-05 7.8340156e-05 8.9330599e-05 1.4844121e-04\n",
      "  7.7085897e-05 6.5119493e-05 9.8221877e-05 2.2798829e-05 1.2683671e-04\n",
      "  3.2161977e-04 2.6153473e-05]]\n"
     ]
    }
   ],
   "source": [
    "out = predictions.argmax()\n",
    "print(le.inverse_transform([out]))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ee61b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 =[\"Une fois que vous connaissez tous les éléments, il n'est pas difficile de rassembler une phrase.\"] #French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ee17e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text2 = tokenizer.texts_to_sequences(text2)\n",
    "test_text2 = tf.keras.preprocessing.sequence.pad_sequences(test_text2, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9213a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model.predict(test_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c834cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['French']\n",
      "[[8.0978347e-04 1.0693547e-03 1.4357541e-02 3.5939406e-04 2.0476719e-03\n",
      "  9.3291909e-01 5.0980627e-04 8.1723952e-04 1.0252260e-02 1.7609925e-03\n",
      "  5.9154304e-03 7.0889835e-04 4.5079188e-03 8.1163947e-04 4.3656286e-03\n",
      "  7.6233491e-04 9.9584563e-03 8.2183664e-04 2.0575712e-03 3.3320291e-03\n",
      "  1.1348643e-03 7.2022399e-04]]\n"
     ]
    }
   ],
   "source": [
    "out2 = predictions2.argmax()\n",
    "print(le.inverse_transform([out2]))\n",
    "print(predictions2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
